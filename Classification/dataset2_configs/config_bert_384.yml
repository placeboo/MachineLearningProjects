dataset:
  name: 'nlp'
  file_path: 'data/dataset2/raw/Youtube-Spam-Dataset.csv'
  output_dir: 'data/dataset2/processed/transformer_384'
  embedding_method: 'transformer'
  rerun: False
  embedding_config:
    max_seq_length: 500
    model_name: 'paraphrase-MiniLM-L3-v2'

models:
  knn:
    param_grid:
      'n_neighbors': [1, 2, 3, 4, 5, 10, 15, 20, 25, 30]
      'weights': [ 'uniform', 'distance' ]
  svm:
    param_grid:
      'kernel': ['rbf', 'sigmoid', 'linear', 'poly']
      'gamma': ['scale', 'auto', 0.1, 0.01]
  nn:
    param_grid:
      'hidden_layer_sizes': [[20], [40], [60], [80], [100], [120], [60, 20], [60, 40], [60, 60]]
      'learning_rate': ['adaptive']
      'learning_rate_init': [1.0, 0.5, 0.1, 0.08, 0.06, 0.04, 0.02, 0.01, .005, .001, .0005, .0001]
  boosting:
    param_grid:
      'n_estimators': [50, 100, 150, 200, 250]
      'max_depth': [3, 5, 7, 9]
random_state: 17
cross_validation:
    n_splits: 5
model_output_dir: 'results/dataset2/model_outputs_bert_384'